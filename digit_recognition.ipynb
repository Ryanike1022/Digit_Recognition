{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1qHUwSUUGqPW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 100, shuffle = True, num_workers = 1)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = 100, shuffle = False, num_workers = 1)"
      ],
      "metadata": {
        "id": "ci-N0fyqy8DA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset.targets.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "439XMjnFG2Oa",
        "outputId": "0e8a198b-8c44-413b-eef2-5527abbd3ee0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1,10,5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, 5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "     x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "     x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
        "     x = x.view(-1, 320)\n",
        "     x = F.relu(self.fc1(x))\n",
        "     x = F.dropout(x, training = self.training)\n",
        "     x = self.fc2(x)\n",
        "\n",
        "     return F.softmax(x)"
      ],
      "metadata": {
        "id": "g7wUUZOpJOYk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(trainloader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f'Train epoch: {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)}({100. * batch_idx / len(trainloader):.0f}%))]')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in testloader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.argmax(dim = 1, keepdim = True)\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(testloader.dataset)\n",
        "  print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)}({100. * correct / len(testloader.dataset):.0f}%)\\n')"
      ],
      "metadata": {
        "id": "ZbnmEPc_iGVk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgdft02uew2f",
        "outputId": "23bbb4b5-3e5d-4350-e6c1-2c8c1011bef9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2760251789.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch: 1 [0/60000(0%))]\n",
            "Train epoch: 1 [2000/60000(3%))]\n",
            "Train epoch: 1 [4000/60000(7%))]\n",
            "Train epoch: 1 [6000/60000(10%))]\n",
            "Train epoch: 1 [8000/60000(13%))]\n",
            "Train epoch: 1 [10000/60000(17%))]\n",
            "Train epoch: 1 [12000/60000(20%))]\n",
            "Train epoch: 1 [14000/60000(23%))]\n",
            "Train epoch: 1 [16000/60000(27%))]\n",
            "Train epoch: 1 [18000/60000(30%))]\n",
            "Train epoch: 1 [20000/60000(33%))]\n",
            "Train epoch: 1 [22000/60000(37%))]\n",
            "Train epoch: 1 [24000/60000(40%))]\n",
            "Train epoch: 1 [26000/60000(43%))]\n",
            "Train epoch: 1 [28000/60000(47%))]\n",
            "Train epoch: 1 [30000/60000(50%))]\n",
            "Train epoch: 1 [32000/60000(53%))]\n",
            "Train epoch: 1 [34000/60000(57%))]\n",
            "Train epoch: 1 [36000/60000(60%))]\n",
            "Train epoch: 1 [38000/60000(63%))]\n",
            "Train epoch: 1 [40000/60000(67%))]\n",
            "Train epoch: 1 [42000/60000(70%))]\n",
            "Train epoch: 1 [44000/60000(73%))]\n",
            "Train epoch: 1 [46000/60000(77%))]\n",
            "Train epoch: 1 [48000/60000(80%))]\n",
            "Train epoch: 1 [50000/60000(83%))]\n",
            "Train epoch: 1 [52000/60000(87%))]\n",
            "Train epoch: 1 [54000/60000(90%))]\n",
            "Train epoch: 1 [56000/60000(93%))]\n",
            "Train epoch: 1 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0154, Accuracy: 9230/10000(92%)\n",
            "\n",
            "Train epoch: 2 [0/60000(0%))]\n",
            "Train epoch: 2 [2000/60000(3%))]\n",
            "Train epoch: 2 [4000/60000(7%))]\n",
            "Train epoch: 2 [6000/60000(10%))]\n",
            "Train epoch: 2 [8000/60000(13%))]\n",
            "Train epoch: 2 [10000/60000(17%))]\n",
            "Train epoch: 2 [12000/60000(20%))]\n",
            "Train epoch: 2 [14000/60000(23%))]\n",
            "Train epoch: 2 [16000/60000(27%))]\n",
            "Train epoch: 2 [18000/60000(30%))]\n",
            "Train epoch: 2 [20000/60000(33%))]\n",
            "Train epoch: 2 [22000/60000(37%))]\n",
            "Train epoch: 2 [24000/60000(40%))]\n",
            "Train epoch: 2 [26000/60000(43%))]\n",
            "Train epoch: 2 [28000/60000(47%))]\n",
            "Train epoch: 2 [30000/60000(50%))]\n",
            "Train epoch: 2 [32000/60000(53%))]\n",
            "Train epoch: 2 [34000/60000(57%))]\n",
            "Train epoch: 2 [36000/60000(60%))]\n",
            "Train epoch: 2 [38000/60000(63%))]\n",
            "Train epoch: 2 [40000/60000(67%))]\n",
            "Train epoch: 2 [42000/60000(70%))]\n",
            "Train epoch: 2 [44000/60000(73%))]\n",
            "Train epoch: 2 [46000/60000(77%))]\n",
            "Train epoch: 2 [48000/60000(80%))]\n",
            "Train epoch: 2 [50000/60000(83%))]\n",
            "Train epoch: 2 [52000/60000(87%))]\n",
            "Train epoch: 2 [54000/60000(90%))]\n",
            "Train epoch: 2 [56000/60000(93%))]\n",
            "Train epoch: 2 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0155, Accuracy: 9122/10000(91%)\n",
            "\n",
            "Train epoch: 3 [0/60000(0%))]\n",
            "Train epoch: 3 [2000/60000(3%))]\n",
            "Train epoch: 3 [4000/60000(7%))]\n",
            "Train epoch: 3 [6000/60000(10%))]\n",
            "Train epoch: 3 [8000/60000(13%))]\n",
            "Train epoch: 3 [10000/60000(17%))]\n",
            "Train epoch: 3 [12000/60000(20%))]\n",
            "Train epoch: 3 [14000/60000(23%))]\n",
            "Train epoch: 3 [16000/60000(27%))]\n",
            "Train epoch: 3 [18000/60000(30%))]\n",
            "Train epoch: 3 [20000/60000(33%))]\n",
            "Train epoch: 3 [22000/60000(37%))]\n",
            "Train epoch: 3 [24000/60000(40%))]\n",
            "Train epoch: 3 [26000/60000(43%))]\n",
            "Train epoch: 3 [28000/60000(47%))]\n",
            "Train epoch: 3 [30000/60000(50%))]\n",
            "Train epoch: 3 [32000/60000(53%))]\n",
            "Train epoch: 3 [34000/60000(57%))]\n",
            "Train epoch: 3 [36000/60000(60%))]\n",
            "Train epoch: 3 [38000/60000(63%))]\n",
            "Train epoch: 3 [40000/60000(67%))]\n",
            "Train epoch: 3 [42000/60000(70%))]\n",
            "Train epoch: 3 [44000/60000(73%))]\n",
            "Train epoch: 3 [46000/60000(77%))]\n",
            "Train epoch: 3 [48000/60000(80%))]\n",
            "Train epoch: 3 [50000/60000(83%))]\n",
            "Train epoch: 3 [52000/60000(87%))]\n",
            "Train epoch: 3 [54000/60000(90%))]\n",
            "Train epoch: 3 [56000/60000(93%))]\n",
            "Train epoch: 3 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0159, Accuracy: 8682/10000(87%)\n",
            "\n",
            "Train epoch: 4 [0/60000(0%))]\n",
            "Train epoch: 4 [2000/60000(3%))]\n",
            "Train epoch: 4 [4000/60000(7%))]\n",
            "Train epoch: 4 [6000/60000(10%))]\n",
            "Train epoch: 4 [8000/60000(13%))]\n",
            "Train epoch: 4 [10000/60000(17%))]\n",
            "Train epoch: 4 [12000/60000(20%))]\n",
            "Train epoch: 4 [14000/60000(23%))]\n",
            "Train epoch: 4 [16000/60000(27%))]\n",
            "Train epoch: 4 [18000/60000(30%))]\n",
            "Train epoch: 4 [20000/60000(33%))]\n",
            "Train epoch: 4 [22000/60000(37%))]\n",
            "Train epoch: 4 [24000/60000(40%))]\n",
            "Train epoch: 4 [26000/60000(43%))]\n",
            "Train epoch: 4 [28000/60000(47%))]\n",
            "Train epoch: 4 [30000/60000(50%))]\n",
            "Train epoch: 4 [32000/60000(53%))]\n",
            "Train epoch: 4 [34000/60000(57%))]\n",
            "Train epoch: 4 [36000/60000(60%))]\n",
            "Train epoch: 4 [38000/60000(63%))]\n",
            "Train epoch: 4 [40000/60000(67%))]\n",
            "Train epoch: 4 [42000/60000(70%))]\n",
            "Train epoch: 4 [44000/60000(73%))]\n",
            "Train epoch: 4 [46000/60000(77%))]\n",
            "Train epoch: 4 [48000/60000(80%))]\n",
            "Train epoch: 4 [50000/60000(83%))]\n",
            "Train epoch: 4 [52000/60000(87%))]\n",
            "Train epoch: 4 [54000/60000(90%))]\n",
            "Train epoch: 4 [56000/60000(93%))]\n",
            "Train epoch: 4 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0155, Accuracy: 9077/10000(91%)\n",
            "\n",
            "Train epoch: 5 [0/60000(0%))]\n",
            "Train epoch: 5 [2000/60000(3%))]\n",
            "Train epoch: 5 [4000/60000(7%))]\n",
            "Train epoch: 5 [6000/60000(10%))]\n",
            "Train epoch: 5 [8000/60000(13%))]\n",
            "Train epoch: 5 [10000/60000(17%))]\n",
            "Train epoch: 5 [12000/60000(20%))]\n",
            "Train epoch: 5 [14000/60000(23%))]\n",
            "Train epoch: 5 [16000/60000(27%))]\n",
            "Train epoch: 5 [18000/60000(30%))]\n",
            "Train epoch: 5 [20000/60000(33%))]\n",
            "Train epoch: 5 [22000/60000(37%))]\n",
            "Train epoch: 5 [24000/60000(40%))]\n",
            "Train epoch: 5 [26000/60000(43%))]\n",
            "Train epoch: 5 [28000/60000(47%))]\n",
            "Train epoch: 5 [30000/60000(50%))]\n",
            "Train epoch: 5 [32000/60000(53%))]\n",
            "Train epoch: 5 [34000/60000(57%))]\n",
            "Train epoch: 5 [36000/60000(60%))]\n",
            "Train epoch: 5 [38000/60000(63%))]\n",
            "Train epoch: 5 [40000/60000(67%))]\n",
            "Train epoch: 5 [42000/60000(70%))]\n",
            "Train epoch: 5 [44000/60000(73%))]\n",
            "Train epoch: 5 [46000/60000(77%))]\n",
            "Train epoch: 5 [48000/60000(80%))]\n",
            "Train epoch: 5 [50000/60000(83%))]\n",
            "Train epoch: 5 [52000/60000(87%))]\n",
            "Train epoch: 5 [54000/60000(90%))]\n",
            "Train epoch: 5 [56000/60000(93%))]\n",
            "Train epoch: 5 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0164, Accuracy: 8241/10000(82%)\n",
            "\n",
            "Train epoch: 6 [0/60000(0%))]\n",
            "Train epoch: 6 [2000/60000(3%))]\n",
            "Train epoch: 6 [4000/60000(7%))]\n",
            "Train epoch: 6 [6000/60000(10%))]\n",
            "Train epoch: 6 [8000/60000(13%))]\n",
            "Train epoch: 6 [10000/60000(17%))]\n",
            "Train epoch: 6 [12000/60000(20%))]\n",
            "Train epoch: 6 [14000/60000(23%))]\n",
            "Train epoch: 6 [16000/60000(27%))]\n",
            "Train epoch: 6 [18000/60000(30%))]\n",
            "Train epoch: 6 [20000/60000(33%))]\n",
            "Train epoch: 6 [22000/60000(37%))]\n",
            "Train epoch: 6 [24000/60000(40%))]\n",
            "Train epoch: 6 [26000/60000(43%))]\n",
            "Train epoch: 6 [28000/60000(47%))]\n",
            "Train epoch: 6 [30000/60000(50%))]\n",
            "Train epoch: 6 [32000/60000(53%))]\n",
            "Train epoch: 6 [34000/60000(57%))]\n",
            "Train epoch: 6 [36000/60000(60%))]\n",
            "Train epoch: 6 [38000/60000(63%))]\n",
            "Train epoch: 6 [40000/60000(67%))]\n",
            "Train epoch: 6 [42000/60000(70%))]\n",
            "Train epoch: 6 [44000/60000(73%))]\n",
            "Train epoch: 6 [46000/60000(77%))]\n",
            "Train epoch: 6 [48000/60000(80%))]\n",
            "Train epoch: 6 [50000/60000(83%))]\n",
            "Train epoch: 6 [52000/60000(87%))]\n",
            "Train epoch: 6 [54000/60000(90%))]\n",
            "Train epoch: 6 [56000/60000(93%))]\n",
            "Train epoch: 6 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0162, Accuracy: 8439/10000(84%)\n",
            "\n",
            "Train epoch: 7 [0/60000(0%))]\n",
            "Train epoch: 7 [2000/60000(3%))]\n",
            "Train epoch: 7 [4000/60000(7%))]\n",
            "Train epoch: 7 [6000/60000(10%))]\n",
            "Train epoch: 7 [8000/60000(13%))]\n",
            "Train epoch: 7 [10000/60000(17%))]\n",
            "Train epoch: 7 [12000/60000(20%))]\n",
            "Train epoch: 7 [14000/60000(23%))]\n",
            "Train epoch: 7 [16000/60000(27%))]\n",
            "Train epoch: 7 [18000/60000(30%))]\n",
            "Train epoch: 7 [20000/60000(33%))]\n",
            "Train epoch: 7 [22000/60000(37%))]\n",
            "Train epoch: 7 [24000/60000(40%))]\n",
            "Train epoch: 7 [26000/60000(43%))]\n",
            "Train epoch: 7 [28000/60000(47%))]\n",
            "Train epoch: 7 [30000/60000(50%))]\n",
            "Train epoch: 7 [32000/60000(53%))]\n",
            "Train epoch: 7 [34000/60000(57%))]\n",
            "Train epoch: 7 [36000/60000(60%))]\n",
            "Train epoch: 7 [38000/60000(63%))]\n",
            "Train epoch: 7 [40000/60000(67%))]\n",
            "Train epoch: 7 [42000/60000(70%))]\n",
            "Train epoch: 7 [44000/60000(73%))]\n",
            "Train epoch: 7 [46000/60000(77%))]\n",
            "Train epoch: 7 [48000/60000(80%))]\n",
            "Train epoch: 7 [50000/60000(83%))]\n",
            "Train epoch: 7 [52000/60000(87%))]\n",
            "Train epoch: 7 [54000/60000(90%))]\n",
            "Train epoch: 7 [56000/60000(93%))]\n",
            "Train epoch: 7 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0157, Accuracy: 8896/10000(89%)\n",
            "\n",
            "Train epoch: 8 [0/60000(0%))]\n",
            "Train epoch: 8 [2000/60000(3%))]\n",
            "Train epoch: 8 [4000/60000(7%))]\n",
            "Train epoch: 8 [6000/60000(10%))]\n",
            "Train epoch: 8 [8000/60000(13%))]\n",
            "Train epoch: 8 [10000/60000(17%))]\n",
            "Train epoch: 8 [12000/60000(20%))]\n",
            "Train epoch: 8 [14000/60000(23%))]\n",
            "Train epoch: 8 [16000/60000(27%))]\n",
            "Train epoch: 8 [18000/60000(30%))]\n",
            "Train epoch: 8 [20000/60000(33%))]\n",
            "Train epoch: 8 [22000/60000(37%))]\n",
            "Train epoch: 8 [24000/60000(40%))]\n",
            "Train epoch: 8 [26000/60000(43%))]\n",
            "Train epoch: 8 [28000/60000(47%))]\n",
            "Train epoch: 8 [30000/60000(50%))]\n",
            "Train epoch: 8 [32000/60000(53%))]\n",
            "Train epoch: 8 [34000/60000(57%))]\n",
            "Train epoch: 8 [36000/60000(60%))]\n",
            "Train epoch: 8 [38000/60000(63%))]\n",
            "Train epoch: 8 [40000/60000(67%))]\n",
            "Train epoch: 8 [42000/60000(70%))]\n",
            "Train epoch: 8 [44000/60000(73%))]\n",
            "Train epoch: 8 [46000/60000(77%))]\n",
            "Train epoch: 8 [48000/60000(80%))]\n",
            "Train epoch: 8 [50000/60000(83%))]\n",
            "Train epoch: 8 [52000/60000(87%))]\n",
            "Train epoch: 8 [54000/60000(90%))]\n",
            "Train epoch: 8 [56000/60000(93%))]\n",
            "Train epoch: 8 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0163, Accuracy: 8323/10000(83%)\n",
            "\n",
            "Train epoch: 9 [0/60000(0%))]\n",
            "Train epoch: 9 [2000/60000(3%))]\n",
            "Train epoch: 9 [4000/60000(7%))]\n",
            "Train epoch: 9 [6000/60000(10%))]\n",
            "Train epoch: 9 [8000/60000(13%))]\n",
            "Train epoch: 9 [10000/60000(17%))]\n",
            "Train epoch: 9 [12000/60000(20%))]\n",
            "Train epoch: 9 [14000/60000(23%))]\n",
            "Train epoch: 9 [16000/60000(27%))]\n",
            "Train epoch: 9 [18000/60000(30%))]\n",
            "Train epoch: 9 [20000/60000(33%))]\n",
            "Train epoch: 9 [22000/60000(37%))]\n",
            "Train epoch: 9 [24000/60000(40%))]\n",
            "Train epoch: 9 [26000/60000(43%))]\n",
            "Train epoch: 9 [28000/60000(47%))]\n",
            "Train epoch: 9 [30000/60000(50%))]\n",
            "Train epoch: 9 [32000/60000(53%))]\n",
            "Train epoch: 9 [34000/60000(57%))]\n",
            "Train epoch: 9 [36000/60000(60%))]\n",
            "Train epoch: 9 [38000/60000(63%))]\n",
            "Train epoch: 9 [40000/60000(67%))]\n",
            "Train epoch: 9 [42000/60000(70%))]\n",
            "Train epoch: 9 [44000/60000(73%))]\n",
            "Train epoch: 9 [46000/60000(77%))]\n",
            "Train epoch: 9 [48000/60000(80%))]\n",
            "Train epoch: 9 [50000/60000(83%))]\n",
            "Train epoch: 9 [52000/60000(87%))]\n",
            "Train epoch: 9 [54000/60000(90%))]\n",
            "Train epoch: 9 [56000/60000(93%))]\n",
            "Train epoch: 9 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0166, Accuracy: 7982/10000(80%)\n",
            "\n",
            "Train epoch: 10 [0/60000(0%))]\n",
            "Train epoch: 10 [2000/60000(3%))]\n",
            "Train epoch: 10 [4000/60000(7%))]\n",
            "Train epoch: 10 [6000/60000(10%))]\n",
            "Train epoch: 10 [8000/60000(13%))]\n",
            "Train epoch: 10 [10000/60000(17%))]\n",
            "Train epoch: 10 [12000/60000(20%))]\n",
            "Train epoch: 10 [14000/60000(23%))]\n",
            "Train epoch: 10 [16000/60000(27%))]\n",
            "Train epoch: 10 [18000/60000(30%))]\n",
            "Train epoch: 10 [20000/60000(33%))]\n",
            "Train epoch: 10 [22000/60000(37%))]\n",
            "Train epoch: 10 [24000/60000(40%))]\n",
            "Train epoch: 10 [26000/60000(43%))]\n",
            "Train epoch: 10 [28000/60000(47%))]\n",
            "Train epoch: 10 [30000/60000(50%))]\n",
            "Train epoch: 10 [32000/60000(53%))]\n",
            "Train epoch: 10 [34000/60000(57%))]\n",
            "Train epoch: 10 [36000/60000(60%))]\n",
            "Train epoch: 10 [38000/60000(63%))]\n",
            "Train epoch: 10 [40000/60000(67%))]\n",
            "Train epoch: 10 [42000/60000(70%))]\n",
            "Train epoch: 10 [44000/60000(73%))]\n",
            "Train epoch: 10 [46000/60000(77%))]\n",
            "Train epoch: 10 [48000/60000(80%))]\n",
            "Train epoch: 10 [50000/60000(83%))]\n",
            "Train epoch: 10 [52000/60000(87%))]\n",
            "Train epoch: 10 [54000/60000(90%))]\n",
            "Train epoch: 10 [56000/60000(93%))]\n",
            "Train epoch: 10 [58000/60000(97%))]\n",
            "\n",
            "Test set: Average loss: 0.0160, Accuracy: 8605/10000(86%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model.eval()\n",
        "data, target = testset[8]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim = 1, keepdim = True)\n",
        "\n",
        "plt.imshow(data.cpu().squeeze(0).squeeze(0), cmap = 'gray')\n",
        "print(f'Prediction: {prediction.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "f8vHlUvZZDMp",
        "outputId": "ddd5af2f-1432-404f-e629-9b5a32c548b6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2760251789.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDlWfG-MbDbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}